{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e81f8fb",
   "metadata": {},
   "source": [
    "# 1. Basic LLM - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "918d490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import nltk\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "#Sample Data\n",
    "sample_text = \"\"\"\n",
    "Once upon a time, in a land far, far away, there lived a king and queen who had a beautiful daughter. The princess was kind and gentle, and everyone loved her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85013ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'upon', 'a', 'time', ',', 'in', 'a', 'land', 'far', ',', 'far', 'away', ',', 'there', 'lived', 'a', 'king', 'and', 'queen', 'who', 'had', 'a', 'beautiful', 'daughter', '.', 'the', 'princess', 'was', 'kind', 'and', 'gentle', ',', 'and', 'everyone', 'loved', 'her', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "nltk.download('punkt')\n",
    "tokens = nltk.word_tokenize(sample_text.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c1b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'collections.Counter'>, {'once': Counter({'upon': 1}), 'upon': Counter({'a': 1}), 'a': Counter({'time': 1, 'land': 1, 'king': 1, 'beautiful': 1}), 'time': Counter({',': 1}), ',': Counter({'in': 1, 'far': 1, 'there': 1, 'and': 1}), 'in': Counter({'a': 1}), 'land': Counter({'far': 1}), 'far': Counter({',': 1, 'away': 1}), 'away': Counter({',': 1}), 'there': Counter({'lived': 1}), 'lived': Counter({'a': 1}), 'king': Counter({'and': 1}), 'and': Counter({'queen': 1, 'gentle': 1, 'everyone': 1}), 'queen': Counter({'who': 1}), 'who': Counter({'had': 1}), 'had': Counter({'a': 1}), 'beautiful': Counter({'daughter': 1}), 'daughter': Counter({'.': 1}), '.': Counter({'the': 1}), 'the': Counter({'princess': 1}), 'princess': Counter({'was': 1}), 'was': Counter({'kind': 1}), 'kind': Counter({'and': 1}), 'gentle': Counter({',': 1}), 'everyone': Counter({'loved': 1}), 'loved': Counter({'her': 1}), 'her': Counter({'.': 1})})\n"
     ]
    }
   ],
   "source": [
    "#Ngrams\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq = defaultdict(Counter)\n",
    "\n",
    "for w1, w2 in bigrams:\n",
    "    bigram_freq[w1][w2] += 1\n",
    "\n",
    "print(bigram_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1befbdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "princess was kind and gentle ,\n"
     ]
    }
   ],
   "source": [
    "#Generating Text\n",
    "def generate_text(seed, n_words):\n",
    "    result = [seed]\n",
    "    for _ in range(n_words):\n",
    "        next_word_options = bigram_freq[result[-1]]\n",
    "        next_word = random.choices(list(next_word_options.keys()), list(next_word_options.values()))[0]\n",
    "        result.append(next_word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "generated_text = generate_text('princess', 5)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f5a24",
   "metadata": {},
   "source": [
    "# 2. Simple LLM Which can answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3de4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import nltk\n",
    "import random\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4bda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset\n",
    "old_text = \"The use of n-grams, particularly bigrams, in natural language processing (NLP) carries great importance by providing valuable insights into the structure and patterns of language, enabling the development of more accurate and efficient NLP systems. N-grams work by analyzing the frequencies of consecutive items, such as words or characters, in a given text. This analysis helps in tasks like language modeling, speech recognition, text prediction, and information retrieval. The benefits of utilizing n-grams include improved language understanding, accurate word prediction, enhanced search accuracy, and faster information retrieval.\"\n",
    "new_text = \"To further enhance the effectiveness of n-grams, one can consider increasing the value of n to include larger sequences of items, such as trigrams or even higher-order n-grams, as it may capture more contextual information. Additionally, considering the size and diversity of the training data used for building n-gram models is important to ensure their applicability across different domains and languages.\"\n",
    "combined_text = old_text + \" \" + new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83cf75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the text\n",
    "sent_tokens = sent_tokenize(combined_text)\n",
    "word_tokens = [word_tokenize(t) for t in sent_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee69bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a trigram model\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "298d3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6890c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the importance\n",
      "Answer: by providing valuable insights into the structure and patterns of language , enabling the development of more accurate and efficient\n",
      "\n",
      "\n",
      "Question: How does it work\n",
      "Answer: by analyzing the frequencies of consecutive items , such as trigrams or even higher-order n-grams , one can consider increasing\n",
      "\n",
      "\n",
      "Question: What are the benefits\n",
      "Answer: of utilizing n-grams include improved language understanding , accurate word prediction , enhanced search accuracy , and information retrieval .\n",
      "\n",
      "\n",
      "Question: How can I improve\n",
      "Answer: applicability across different domains and languages . </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n",
      "Question: What should I consider to increase the performance?\n",
      "Answer: it may capture more contextual information . </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate text with various questions\n",
    "def generate_text(prompt, num_words, model):\n",
    "    word_list = model.generate(num_words, text_seed=prompt.split())\n",
    "    response = ' '.join(word_list)\n",
    "    return response\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What is the importance\",\n",
    "    \"How does it work\",\n",
    "    \"What are the benefits\",\n",
    "    \"How can I improve\",\n",
    "    \"What should I consider to increase the performance?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {generate_text(question, 20, model)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1dac0",
   "metadata": {},
   "source": [
    "# 3. Simple Bigram LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "008075e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import nltk\n",
    "from nltk import bigrams, FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a04f1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "text = \"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence \\\n",
    "concerned with the interactions between computers and human language. In particular, it focuses on programming \\\n",
    "computers to process and analyze large amounts of natural language data.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20e6773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bigrams and their frequency distribution\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq_dist = FreqDist(bigrams)\n",
    "\n",
    "# Prepare the dataset for training\n",
    "train_data, padded_sents = padded_everygram_pipeline(2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "affb0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bigram model\n",
    "model = MLE(2)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b39b9f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is natural language processing?\n",
      "A: ? </s> p u a t a g e r\n",
      "\n",
      "Q: How does artificial intelligence relate to linguistics?\n",
      "A: How n d </s> <s> b e n </s> d\n",
      "\n",
      "Q: Can computers understand human language?\n",
      "A: understand p r a m p r s </s> s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model, num_words, seed_word):\n",
    "    sentence = [seed_word]\n",
    "    for _ in range(num_words - 1):\n",
    "        next_word = model.generate(1, text_seed=sentence)\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example questions to the model\n",
    "questions = [\n",
    "    \"What is natural language processing?\",\n",
    "    \"How does artificial intelligence relate to linguistics?\",\n",
    "    \"Can computers understand human language?\",\n",
    "]\n",
    "\n",
    "# Generate answers for the questions\n",
    "for question in questions:\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    seed_word = choice(tokens)\n",
    "    generated_sentence = generate_sentence(model, 10, seed_word)\n",
    "    print(f\"Q: {question}\\nA: {generated_sentence}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
